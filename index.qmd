---
title: "Random Forest Challenge"
subtitle: "The Power of Weak Learners"
format:
  html: default
execute:
  echo: false
  eval: true
---

# üå≤ Random Forest Challenge - The Power of Weak Learners

::: {.callout-important}
## üìä Challenge Requirements In [Student Analysis Section](#student-analysis-section)

Navigate to the [Student Analysis Section](#student-analysis-section) to see the challenge requirements.

:::

## The Problem: Can Many Weak Learners Beat One Strong Learner?

**Core Question:** How does the number of trees in a random forest affect predictive accuracy, and how do random forests compare to simpler approaches like linear regression?

**The Challenge:** Individual decision trees are "weak learners" with limited predictive power. Random forests combine many weak trees to create a "strong learner" that generalizes better. But how many trees do we need? Do more trees always mean better performance, or is there a point of diminishing returns?

**Our Approach:** We'll compare random forests with different numbers of trees against linear regression and individual decision trees to understand the trade-offs between complexity and performance **for this dataset**.

::: {.callout-warning}
## ‚ö†Ô∏è AI Partnership Required

This challenge pushes boundaries intentionally. You'll tackle problems that normally require weeks of study, but with Cursor AI as your partner (and your brain keeping it honest), you can accomplish more than you thought possible.

**The new reality:** The four stages of competence are Ignorance ‚Üí Awareness ‚Üí Learning ‚Üí Mastery. AI lets us produce Mastery-level work while operating primarily in the Awareness stage. I focus on awareness training, you leverage AI for execution, and together we create outputs that used to require years of dedicated study.
:::

## Data and Methodology

We analyze the Ames Housing dataset, which contains detailed information about residential properties sold in Ames, Iowa from 2006 to 2010. This dataset is ideal for our analysis because:

- **Anticipated Non-linear Relationships:** Real estate prices have complex, non-linear relationships between features (e.g., square footage in wealthy vs. poor zip codes affects price differently)
- **Mixed Data Types:** Contains both categorical (zipCode) and numerical variables
- **Real-world Complexity:** Captures the kind of messy, real-world data where ensemble methods excel

Since we anticipate non-linear relationships, random forests are well-suited to model the relationship between features and sale price.

::: {.panel-tabset}

### Package Installation

```{r}
#| label: install-packages
#| echo: false
#| message: true
#| warning: true

# Set CRAN mirror
options(repos = c(CRAN = "https://cran.rstudio.com/"))

# Check if packages are already installed, install only if needed
if (!require(tidyverse, quietly = TRUE)) {
  install.packages("tidyverse")
}
if (!require(randomForest, quietly = TRUE)) {
  install.packages("randomForest")
}
if (!require(languageserver, quietly = TRUE)) {
  install.packages("languageserver")
}
if (!require(gridExtra, quietly = TRUE)) {
  install.packages("gridExtra")
}
if (!require(rpart, quietly = TRUE)) {
  install.packages("rpart")
}

```

### R

```{r}
#| label: load-and-model-r
#| echo: false
#| message: false
#| warning: false

# Set up error handling
options(error = function() {
  cat("Error occurred in R code\n")
  traceback()
})

# Load libraries with error handling
tryCatch({
  suppressPackageStartupMessages(library(tidyverse))
  suppressPackageStartupMessages(library(randomForest))
  cat("‚úì Libraries loaded successfully\n")
}, error = function(e) {
  cat("‚úó Error loading libraries:", e$message, "\n")
  stop("Failed to load required libraries")
})

# Load data with error handling
tryCatch({
  cat("Loading data...\n")
  sales_data <- read.csv("https://raw.githubusercontent.com/flyaflya/buad442Fall2025/refs/heads/main/datasets/salesPriceData.csv")
  cat("‚úì Data loaded successfully:", nrow(sales_data), "rows\n")
}, error = function(e) {
  cat("‚úó Error loading data:", e$message, "\n")
  stop("Failed to load data")
})

# Prepare model data with error handling
tryCatch({
  cat("Preparing model data...\n")
  model_data <- sales_data %>%
    select(SalePrice, LotArea, YearBuilt, GrLivArea, FullBath, HalfBath, 
           BedroomAbvGr, TotRmsAbvGrd, GarageCars, zipCode) %>%
    mutate(zipCode = as.factor(zipCode)) %>%
    na.omit()
  
  cat("‚úì Data prepared with zipCode as categorical variable\n")
  cat("Number of unique zip codes:", length(unique(model_data$zipCode)), "\n")
  cat("Dataset size:", nrow(model_data), "rows\n")
}, error = function(e) {
  cat("‚úó Error preparing data:", e$message, "\n")
  stop("Failed to prepare data")
})

# Split data with error handling
tryCatch({
  set.seed(123)
  train_indices <- sample(1:nrow(model_data), 0.8 * nrow(model_data))
  train_data <- model_data[train_indices, ]
  test_data <- model_data[-train_indices, ]
  
  cat("‚úì Data split successfully\n")
  cat("Training data size:", nrow(train_data), "rows\n")
  cat("Test data size:", nrow(test_data), "rows\n")
}, error = function(e) {
  cat("‚úó Error splitting data:", e$message, "\n")
  stop("Failed to split data")
})

# Build random forests with error handling
tryCatch({
  cat("Building random forest models...\n")
  
  cat("Building 1-tree model...\n")
  rf_1 <<- randomForest(SalePrice ~ ., data = train_data, ntree = 1, mtry = 3, seed = 123)
  cat("‚úì 1-tree model built\n")
  
  cat("Building 5-tree model...\n")
  rf_5 <<- randomForest(SalePrice ~ ., data = train_data, ntree = 5, mtry = 3, seed = 123)
  cat("‚úì 5-tree model built\n")
  
  cat("Building 25-tree model...\n")
  rf_25 <<- randomForest(SalePrice ~ ., data = train_data, ntree = 25, mtry = 3, seed = 123)
  cat("‚úì 25-tree model built\n")
  
  cat("Building 100-tree model...\n")
  rf_100 <<- randomForest(SalePrice ~ ., data = train_data, ntree = 100, mtry = 3, seed = 123)
  cat("‚úì 100-tree model built\n")
  
  cat("‚úì All models built successfully!\n")
}, error = function(e) {
  cat("‚úó Error building models:", e$message, "\n")
  stop("Failed to build random forest models")
})

```



```{python}
#| label: load-and-model-python
#| echo: false

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Load data
sales_data = pd.read_csv("https://raw.githubusercontent.com/flyaflya/buad442Fall2025/refs/heads/main/datasets/salesPriceData.csv")

# Prepare model data
model_vars = ['SalePrice', 'LotArea', 'YearBuilt', 'GrLivArea', 'FullBath', 
              'HalfBath', 'BedroomAbvGr', 'TotRmsAbvGrd', 'GarageCars', 'zipCode']
model_data = sales_data[model_vars].dropna()

# Convert zipCode to categorical variable - important for proper modeling
model_data['zipCode'] = model_data['zipCode'].astype('category')

# Split data
X = model_data.drop('SalePrice', axis=1)
y = model_data['SalePrice']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)

# Build random forests with different numbers of trees (with corrected categorical zipCode)
rf_1 = RandomForestRegressor(n_estimators=1, max_features=3, random_state=123)
rf_5 = RandomForestRegressor(n_estimators=5, max_features=3, random_state=123)
rf_25 = RandomForestRegressor(n_estimators=25, max_features=3, random_state=123)
rf_100 = RandomForestRegressor(n_estimators=100, max_features=3, random_state=123)
rf_500 = RandomForestRegressor(n_estimators=500, max_features=3, random_state=123)
rf_1000 = RandomForestRegressor(n_estimators=1000, max_features=3, random_state=123)
rf_2000 = RandomForestRegressor(n_estimators=2000, max_features=3, random_state=123)
rf_5000 = RandomForestRegressor(n_estimators=5000, max_features=3, random_state=123)

# Fit all models
rf_1.fit(X_train, y_train)
rf_5.fit(X_train, y_train)
rf_25.fit(X_train, y_train)
rf_100.fit(X_train, y_train)
rf_500.fit(X_train, y_train)
rf_1000.fit(X_train, y_train)
rf_2000.fit(X_train, y_train)
rf_5000.fit(X_train, y_train)
```

:::

## Results: The Power of Ensemble Learning

Our analysis reveals a clear pattern: **more trees consistently improve performance**. Let's examine the results and understand why this happens.

### Student Analysis Section: The Power of More Trees {#student-analysis-section}

### 1. The Power of More Trees Visualization
::: {.panel-tabset}

### R

```{r}
#| label: performance-comparison-r
#| echo: false
#| message: false
#| warning: false
#| fig-width: 10
#| fig-height: 6

# Calculate predictions and performance metrics for test data
predictions_1_test <- predict(rf_1, test_data)
predictions_5_test <- predict(rf_5, test_data)
predictions_25_test <- predict(rf_25, test_data)
predictions_100_test <- predict(rf_100, test_data)
# predictions_500_test <- predict(rf_500, test_data)
# predictions_1000_test <- predict(rf_1000, test_data)

# Calculate predictions for training data
predictions_1_train <- predict(rf_1, train_data)
predictions_5_train <- predict(rf_5, train_data)
predictions_25_train <- predict(rf_25, train_data)
predictions_100_train <- predict(rf_100, train_data)
# predictions_500_train <- predict(rf_500, train_data)
# predictions_1000_train <- predict(rf_1000, train_data)

# Calculate RMSE for test data
rmse_1_test <- sqrt(mean((test_data$SalePrice - predictions_1_test)^2))
rmse_5_test <- sqrt(mean((test_data$SalePrice - predictions_5_test)^2))
rmse_25_test <- sqrt(mean((test_data$SalePrice - predictions_25_test)^2))
rmse_100_test <- sqrt(mean((test_data$SalePrice - predictions_100_test)^2))
# rmse_500_test <- sqrt(mean((test_data$SalePrice - predictions_500_test)^2))
# rmse_1000_test <- sqrt(mean((test_data$SalePrice - predictions_1000_test)^2))

# Calculate RMSE for training data
rmse_1_train <- sqrt(mean((train_data$SalePrice - predictions_1_train)^2))
rmse_5_train <- sqrt(mean((train_data$SalePrice - predictions_5_train)^2))
rmse_25_train <- sqrt(mean((train_data$SalePrice - predictions_25_train)^2))
rmse_100_train <- sqrt(mean((train_data$SalePrice - predictions_100_train)^2))
# rmse_500_train <- sqrt(mean((train_data$SalePrice - predictions_500_train)^2))
# rmse_1000_train <- sqrt(mean((train_data$SalePrice - predictions_1000_train)^2))

# Calculate R-squared
r2_1 <- 1 - sum((test_data$SalePrice - predictions_1_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_5 <- 1 - sum((test_data$SalePrice - predictions_5_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_25 <- 1 - sum((test_data$SalePrice - predictions_25_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_100 <- 1 - sum((test_data$SalePrice - predictions_100_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
# r2_500 <- 1 - sum((test_data$SalePrice - predictions_500_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
# r2_1000 <- 1 - sum((test_data$SalePrice - predictions_1000_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)

# Create performance comparison
performance_df <- data.frame(
  Trees = c(1, 5, 25, 100),
  RMSE_Test = c(rmse_1_test, rmse_5_test, rmse_25_test, rmse_100_test),
  RMSE_Train = c(rmse_1_train, rmse_5_train, rmse_25_train, rmse_100_train),
  R_squared = c(r2_1, r2_5, r2_25, r2_100)
)

print(performance_df)
```

### Visualization

```{r}
#| label: power-of-trees-visualization
#| echo: false
#| message: false
#| warning: false
#| fig-width: 12
#| fig-height: 8

# Create comprehensive visualization showing the power of more trees
library(ggplot2)
if (!require(gridExtra, quietly = TRUE)) {
  install.packages("gridExtra")
  library(gridExtra)
}

# Prepare data for visualization
trees <- c(1, 5, 25, 100)
rmse_test <- c(rmse_1_test, rmse_5_test, rmse_25_test, rmse_100_test)
rmse_train <- c(rmse_1_train, rmse_5_train, rmse_25_train, rmse_100_train)
r2_values <- c(r2_1, r2_5, r2_25, r2_100)

# Create data frame for plotting
plot_data <- data.frame(
  Trees = rep(trees, 3),
  Value = c(rmse_test, rmse_train, r2_values),
  Metric = rep(c("RMSE_Test", "RMSE_Train", "R_squared"), each = length(trees))
)

# Create RMSE plot
rmse_plot <- ggplot(plot_data[plot_data$Metric %in% c("RMSE_Test", "RMSE_Train"), ], 
                    aes(x = Trees, y = Value, color = Metric)) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  scale_x_log10() +
  scale_color_manual(values = c("RMSE_Test" = "#E31A1C", "RMSE_Train" = "#1F78B4"),
                     labels = c("Test Data", "Training Data")) +
  labs(
    title = "RMSE vs Number of Trees",
    subtitle = "Lower RMSE indicates better predictive performance",
    x = "Number of Trees (log scale)",
    y = "Root Mean Square Error (RMSE)",
    color = "Dataset"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12, color = "gray60"),
    axis.title = element_text(size = 12),
    legend.position = "bottom",
    panel.grid.minor = element_blank()
  ) +
  scale_y_continuous(labels = scales::comma_format())

# Create R-squared plot
r2_plot <- ggplot(plot_data[plot_data$Metric == "R_squared", ], 
                  aes(x = Trees, y = Value)) +
  geom_line(color = "#2E8B57", size = 1.2) +
  geom_point(color = "#2E8B57", size = 3) +
  scale_x_log10() +
  labs(
    title = "R-squared vs Number of Trees",
    subtitle = "Higher R-squared indicates better model fit",
    x = "Number of Trees (log scale)",
    y = "R-squared"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12, color = "gray60"),
    axis.title = element_text(size = 12),
    panel.grid.minor = element_blank()
  ) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1))

# Combine plots
grid.arrange(rmse_plot, r2_plot, ncol = 2)
```

### Analysis/Discussion
After reviewing the plots, we can see that the most dramatic improvements in performance occurs between 1 and 5 trees. We know this because the graph has the steepest slope between those two points for both RMSE and R-squared. Moreover, the training data's RMSE decreased from approximately 28,000 to 22,000 and the testing data's RMSE decreased from approximately 45,000 to 37,000. In addition, the R-squared saw the most dramatic improvements between 1 and 8 trees, where it went from approximately 72% to 81%.

As we added more trees into the model, we found that RMSE and R-squared both showed diminishing returns. We can see this because the slope of the graph becomes less steep as the number of trees increases. This may be because as the model becomes more complex, it starts to overfit the data.
:::

### 2. Overfitting Analysis Visualization

::: {.panel-tabset}

### Visualization

```{r}
#| label: overfitting-analysis
#| echo: false
#| message: false
#| warning: false
#| fig-width: 14
#| fig-height: 6

# Load required libraries
library(rpart)
library(ggplot2)
if (!require(gridExtra, quietly = TRUE)) {
  install.packages("gridExtra")
  library(gridExtra)
}

# Prepare data for overfitting analysis
# Use the same train/test split as before
set.seed(123)
train_indices <- sample(1:nrow(model_data), 0.8 * nrow(model_data))
train_data <- model_data[train_indices, ]
test_data <- model_data[-train_indices, ]

# Decision Trees: Test different max depths
max_depths <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 20)
dt_train_rmse <- numeric(length(max_depths))
dt_test_rmse <- numeric(length(max_depths))

for (i in seq_along(max_depths)) {
  # Build decision tree with specific max depth
  dt_model <- rpart(SalePrice ~ ., data = train_data, 
                   control = rpart.control(maxdepth = max_depths[i]))
  
  # Calculate predictions
  dt_train_pred <- predict(dt_model, train_data)
  dt_test_pred <- predict(dt_model, test_data)
  
  # Calculate RMSE
  dt_train_rmse[i] <- sqrt(mean((train_data$SalePrice - dt_train_pred)^2))
  dt_test_rmse[i] <- sqrt(mean((test_data$SalePrice - dt_test_pred)^2))
}

# Random Forests: Test different numbers of trees
rf_trees <- c(1, 2, 3, 4, 5, 10, 15, 20, 25, 30, 40, 50, 75, 100)
rf_train_rmse <- numeric(length(rf_trees))
rf_test_rmse <- numeric(length(rf_trees))

for (i in seq_along(rf_trees)) {
  # Build random forest with specific number of trees
  rf_model <- randomForest(SalePrice ~ ., data = train_data, 
                          ntree = rf_trees[i], mtry = 3, seed = 123)
  
  # Calculate predictions
  rf_train_pred <- predict(rf_model, train_data)
  rf_test_pred <- predict(rf_model, test_data)
  
  # Calculate RMSE
  rf_train_rmse[i] <- sqrt(mean((train_data$SalePrice - rf_train_pred)^2))
  rf_test_rmse[i] <- sqrt(mean((test_data$SalePrice - rf_test_pred)^2))
}

# Create data frames for plotting
dt_data <- data.frame(
  Complexity = max_depths,
  Train_RMSE = dt_train_rmse,
  Test_RMSE = dt_test_rmse,
  Model_Type = "Decision Tree"
)

rf_data <- data.frame(
  Complexity = rf_trees,
  Train_RMSE = rf_train_rmse,
  Test_RMSE = rf_test_rmse,
  Model_Type = "Random Forest"
)

# Find common y-axis limits for fair comparison
all_rmse_values <- c(dt_train_rmse, dt_test_rmse, rf_train_rmse, rf_test_rmse)
y_min <- min(all_rmse_values) * 0.95
y_max <- max(all_rmse_values) * 1.05

# Create Decision Tree plot
dt_plot <- ggplot(dt_data, aes(x = Complexity)) +
  geom_line(aes(y = Train_RMSE, color = "Training"), size = 1.2) +
  geom_line(aes(y = Test_RMSE, color = "Test"), size = 1.2) +
  geom_point(aes(y = Train_RMSE, color = "Training"), size = 2) +
  geom_point(aes(y = Test_RMSE, color = "Test"), size = 2) +
  scale_color_manual(values = c("Training" = "#1F78B4", "Test" = "#E31A1C")) +
  labs(
    title = "Decision Trees: Overfitting with Complexity",
    subtitle = "Training and Test RMSE vs Max Depth",
    x = "Max Depth (Tree Complexity)",
    y = "Root Mean Square Error (RMSE)",
    color = "Dataset"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12, color = "gray60"),
    axis.title = element_text(size = 12),
    legend.position = "bottom",
    panel.grid.minor = element_blank()
  ) +
  scale_y_continuous(labels = scales::comma_format(), limits = c(y_min, y_max)) +
  scale_x_continuous(breaks = c(1, 5, 10, 15, 20))

# Create Random Forest plot
rf_plot <- ggplot(rf_data, aes(x = Complexity)) +
  geom_line(aes(y = Train_RMSE, color = "Training"), size = 1.2) +
  geom_line(aes(y = Test_RMSE, color = "Test"), size = 1.2) +
  geom_point(aes(y = Train_RMSE, color = "Training"), size = 2) +
  geom_point(aes(y = Test_RMSE, color = "Test"), size = 2) +
  scale_color_manual(values = c("Training" = "#1F78B4", "Test" = "#E31A1C")) +
  scale_x_log10() +
  labs(
    title = "Random Forests: No Overfitting with More Trees",
    subtitle = "Training and Test RMSE vs Number of Trees",
    x = "Number of Trees (log scale)",
    y = "Root Mean Square Error (RMSE)",
    color = "Dataset"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12, color = "gray60"),
    axis.title = element_text(size = 12),
    legend.position = "bottom",
    panel.grid.minor = element_blank()
  ) +
  scale_y_continuous(labels = scales::comma_format(), limits = c(y_min, y_max))

# Combine plots side by side
grid.arrange(dt_plot, rf_plot, ncol = 2)
```

### Analysis/Discussion

In the first graph, we can see the individual decision trees overfitting as they become more complex. When max depth increases, the RMSE does not decrease and stays stagnant for both the training and test data. Moreover, when we allow max depth to increase without adding any constraints, the model starts to overfit the data because it desperately tries to split on the same datapoints over and over again causing redundancies within the trees.

On the contrary, the random forests model does not suffer from the same overfitting problem because each tree is built on a different subset of the data. This prevents the model from overfitting the data because it's not trying to split on the same datapoints but rather averages out the predictions of the individual tree's results. We can see this in the graph where when we increase the number of trees, the RMSE doesn't flatline like it did with the individual decision tree.

As mentioned before, the mechanisms that prevent overfitting in random forests involve bootstrapping which is a resampling technique that takes multiple different training datasets to train many individual decision trees. During this bootstrapping step, the features selected are randomly selected which is why it is important to set a seed before curating the model. Without the seed, we would find different results every time we run the code. Afterwards, the model averages up the results of the many decision trees it made and creates one final model based on those many bootstrapped decision trees.
:::

### 3. Linear Regression vs Random Forest Comparison

::: {.panel-tabset}

### Comparison Table

```{r}
#| label: comparison-table
#| echo: false
#| message: false
#| warning: false

# Ensure required models/data exist from earlier chunks
# Fit linear regression baseline
lm_model <- lm(SalePrice ~ ., data = train_data)
lm_pred_test <- predict(lm_model, test_data)
rmse_lm <- sqrt(mean((test_data$SalePrice - lm_pred_test)^2))

# Use existing rf_1 and rf_100, train rf_1000
rf_1000 <- randomForest(SalePrice ~ ., data = train_data, ntree = 1000, mtry = 3, seed = 123)

rf1_pred_test <- predict(rf_1, test_data)
rf100_pred_test <- predict(rf_100, test_data)
rf1000_pred_test <- predict(rf_1000, test_data)

rmse_rf1 <- sqrt(mean((test_data$SalePrice - rf1_pred_test)^2))
rmse_rf100 <- sqrt(mean((test_data$SalePrice - rf100_pred_test)^2))
rmse_rf1000 <- sqrt(mean((test_data$SalePrice - rf1000_pred_test)^2))

# Build comparison table with improvements vs Linear Regression
comparison_df <- data.frame(
  Model = c("Linear Regression", "Random Forest (1 tree)", "Random Forest (100 trees)", "Random Forest (1000 trees)"),
  RMSE = c(rmse_lm, rmse_rf1, rmse_rf100, rmse_rf1000)
)

comparison_df$Improvement_vs_Linear <- (comparison_df$RMSE[1] - comparison_df$RMSE) / comparison_df$RMSE[1] * 100

# Pretty print
comparison_df$RMSE <- scales::comma(round(comparison_df$RMSE, 2))
comparison_df$Improvement_vs_Linear <- paste0(round(comparison_df$Improvement_vs_Linear, 1), "%")

knitr::kable(comparison_df, align = c('l','r','r'), caption = "Model RMSE and % Improvement vs Linear Regression (lower RMSE is better)")
```

### Analysis/Discussion

As we increase the number of trees in the random forest model, we see a decrease in the RMSE which is a good thing since it means the model is able to predict the test data more accurately. When we switch to 100 trees from linear regression, we see the RMSE to be about the same with only a 1.9% difference between the two models. Random forests added complexity is worth it when we have a dataset that is not linearly separable. However, there is a trade off between interpretability and performance. The random forest model is more difficult to interpret than the linear regression model but it's able to predict the data more accurately in a non-linear way. Therefore, we traded a worse understanding model for a better performing one (vise versa is true for linear regression model).
:::

**Your Task:** Create visualizations and analysis to demonstrate the power of ensemble learning. You'll need to create three key components:

### 1. The Power of More Trees Visualization

**Create a visualization showing:**
- RMSE vs Number of Trees (both training and test data)
- R-squared vs Number of Trees
- Do not `echo` the code that creates the visualization

**Add Brief Discussion of the Visualization**
- Discuss where the most dramatic improvement in performance occurs as you add more trees, how dramatic is it?
- Discuss diminishing returns as you add more trees

::: {.callout-important}
## üìä Visualization Requirements

Create two plots:
1. **RMSE Plot:** Show how RMSE decreases with more trees (both training and test)
2. **R-squared Plot:** Show how R-squared increases with more trees

Use log scale on x-axis to better show the relationship across the range of tree counts.
:::

### 2. Overfitting Visualization and Analysis

**Your Task:** Compare decision trees vs random forests in terms of overfitting.

**Create one visualization with two side-by-side plots showing:**
- Decision trees: How performance changes with tree complexity (max depth)
- Random forests: How performance changes with number of trees

**Your analysis should explain:**
- Why individual decision trees overfit as they become more complex
- Why random forests don't suffer from the same overfitting problem
- The mechanisms that prevent overfitting in random forests (bootstrap sampling, random feature selection, averaging)

::: {.callout-important}
## üìä Overfitting Analysis Requirements

Create a side-by-side comparison showing:
1. **Decision Trees:** Training vs Test RMSE as max depth increases (showing overfitting)
2. **Random Forests:** Training vs Test RMSE as number of trees increases (no overfitting)

- Use the same y-axis limits for both side-by-side plots so it clearly shows whether random forests outperform decision trees.
- Do not `echo` the code that creates the visualization
:::


### 3. Linear Regression vs Random Forest Comparison

**Your Task:** Compare random forests to linear regression baseline.

**Create a comparison table showing:**
- Linear Regression RMSE
- Random Forest (1 tree) RMSE  
- Random Forest (100 trees) RMSE
- Random Forest (1000 trees) RMSE

**Your analysis should address:**
- The improvement in RMSE when going from 1 tree to 100 trees
- Whether switching from linear regression to 100-tree random forest shows similar improvement
- When random forests are worth the added complexity vs linear regression
- The trade-offs between interpretability and performance

::: {.callout-important}
## üìä Comparison Requirements

Create a clear table comparing:

- Linear Regression
- Random Forest (1 tree)
- Random Forest (100 trees) 
- Random Forest (1000 trees)

Include percentage improvements over linear regression for each random forest model.
:::



## Challenge Requirements üìã

### Minimum Requirements for Any Points on Challenge

1. **Create a GitHub Pages Site:** Use the starter repository (see Repository Setup section below) to begin with a working template. The repository includes all the analysis code and visualizations above.  Use just one language for the analysis and visualizations, delete the other language and omit the panel tabsets.

2. **Add Analysis and Visualizations:** Complete the three analysis sections above with your own code and insights.

3. **GitHub Repository:** Use your forked repository (from the starter repository) named "randomForestChallenge" in your GitHub account.

4. **GitHub Pages Setup:** The repository should be made the source of your github pages:

   - Go to your repository settings (click the "Settings" tab in your GitHub repository)
   - Scroll down to the "Pages" section in the left sidebar
   - Under "Source", select "Deploy from a branch"
   - Choose "main" branch and "/ (root)" folder
   - Click "Save"
   - Your site will be available at: `https://[your-username].github.io/randomForestChallenge/`
   - **Note:** It may take a few minutes for the site to become available after enabling Pages

## Getting Started: Repository Setup üöÄ

::: {.callout-important}
## üìÅ Quick Start with Starter Repository

**Step 1:** Fork the starter repository to your github account at [https://github.com/flyaflya/randomForestChallenge.git](https://github.com/flyaflya/randomForestChallenge.git)

**Step 2:** Clone your fork locally using Cursor (or VS Code)

**Step 3:** You're ready to start! The repository includes pre-loaded data and a working template with all the analysis above.
:::

::: {.callout-tip}
## üí° Why Use the Starter Repository?

**Benefits:**

- **Pre-loaded data:** All required data and analysis code is included
- **Working template:** Basic Quarto structure (`index.qmd`) is ready
- **No setup errors:** Avoid common data loading issues
- **Focus on analysis:** Spend time on the visualizations and analysis, not data preparation
:::

### Getting Started Tips

::: {.callout-note}
## üéØ Navy SEALs Motto

> "Slow is Smooth and Smooth is Fast"

*Take your time to understand the random forest mechanics, plan your approach carefully, and execute with precision. Rushing through this challenge will only lead to errors and confusion.*
:::

::: {.callout-warning}
## üíæ Important: Save Your Work Frequently!

**Before you start:** Make sure to commit your work often using the Source Control panel in Cursor (Ctrl+Shift+G or Cmd+Shift+G). This prevents the AI from overwriting your progress and ensures you don't lose your work.

**Commit after each major step:**

- After adding your visualizations
- After adding your analysis
- After rendering to HTML
- Before asking the AI for help with new code

**How to commit:**

1. Open Source Control panel (Ctrl+Shift+G)
2. Stage your changes (+ button)
3. Write a descriptive commit message
4. Click the checkmark to commit

*Remember: Frequent commits are your safety net!*
:::

## Grading Rubric üéì

::: {.callout-important}
## üìä What You're Really Being Graded On

**This is an investigative report, not a coding exercise.** You're analyzing random forest models and reporting your findings like a professional analyst would. Think of this as a brief you'd write for a client or manager about the power of ensemble learning and when to use random forests vs simpler approaches.

**What makes a great report:**

- **Clear narrative:** Tell the story of what you discovered about ensemble learning
- **Insightful analysis:** Focus on the most interesting findings about random forest performance
- **Professional presentation:** Clean, readable, and engaging
- **Concise conclusions:** No AI babble or unnecessary technical jargon
- **Human insights:** Your interpretation of what the performance improvements actually mean
- **Practical implications:** When random forests are worth the added complexity

**What we're looking for:** A compelling 2-3 minute read that demonstrates both the power of ensemble learning and the importance of choosing the right tool for the job.
:::

### Questions to Answer for 75% Grade on Challenge

1. **Power of More Trees Analysis:** Provide a clear, well-reasoned analysis of how random forest performance improves with more trees. Your analysis should demonstrate understanding of ensemble learning principles and diminishing returns.

### Questions to Answer for 85% Grade on Challenge

2. **Overfitting Analysis:** Provide a thorough analysis comparing decision trees vs random forests in terms of overfitting. Your analysis should explain why individual trees overfit while random forests don't, and the mechanisms that prevent overfitting in ensemble methods.

### Questions to Answer for 95% Grade on Challenge

3. **Linear Regression Comparison:** Your analysis should include a clear comparison table and discussion of when random forests are worth the added complexity vs linear regression. Focus on practical implications for real-world applications.

### Questions to Answer for 100% Grade on Challenge

4. **Professional Presentation:** Your analysis should be written in a professional, engaging style that would be appropriate for a business audience. Use clear visualizations and focus on practical insights rather than technical jargon.

## Submission Checklist ‚úÖ

**Minimum Requirements (Required for Any Points):**

- [ ] Forked starter repository from [https://github.com/flyaflya/randomForestChallenge.git](https://github.com/flyaflya/randomForestChallenge.git)
- [ ] Cloned repository locally using Cursor (or VS Code)
- [ ] Completed all three analysis sections with visualizations
- [ ] Document rendered to HTML successfully
- [ ] HTML files uploaded to your forked repository
- [ ] GitHub Pages enabled and working
- [ ] Site accessible at `https://[your-username].github.io/randomForestChallenge/`

**75% Grade Requirements:**

- [ ] Clear analysis of how random forest performance improves with more trees
- [ ] Discussion of diminishing returns in ensemble learning

**85% Grade Requirements:**

- [ ] Thorough overfitting analysis comparing decision trees vs random forests
- [ ] Explanation of mechanisms that prevent overfitting in random forests

**95% Grade Requirements:**

- [ ] Complete linear regression comparison with clear table
- [ ] Discussion of when random forests are worth the complexity

**100% Grade Requirements:**

- [ ] Professional presentation style appropriate for business audience
- [ ] Clear, engaging narrative that tells a compelling story
- [ ] Practical insights that would help a real data scientist

**Report Quality (Critical for Higher Grades):**

- [ ] Clear, engaging narrative that tells a story
- [ ] Focus on the most interesting findings about ensemble learning
- [ ] Professional writing style (no AI-generated fluff)
- [ ] Concise analysis that gets to the point
- [ ] Practical insights that would help a real data scientist
- [ ] Well-designed visualizations that support your analysis

